{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer는 이름 그대로 단어가 나온 횟수를 세는 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "count_vector = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "# 이렇게 우선 단어 사전을 만들어줘야한다.\n",
    "count_vector.fit(text_data)\n",
    "print(count_vector.vocabulary_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]] # ['나는 배가 고프다']\n",
    "print(count_vector.transform(sentence).toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF는 특정한 값을 사용해서 텍스트 데이터의 특징을 추출하는 방법\n",
    "TF(Term Frequency)란 특정 단어가 하나의 데이터 안에서 등장하는 횟수\n",
    "DF(Document Frequency)는 문서 빈도 값으로, 특정 단어가 여러 데이터에 자주 등장하는지를 알려주는 지표.\n",
    "\n",
    "IDF(Inverse Document Frequency)는 이 값에 역수를 취해서 구할 수 있으며, 특정 단어가 다른 데이터에 등장하지 않을수록 값이 커진다는 것을 의미.\n",
    "\n",
    "TF-IDF란 이 두 값을 곱해서 사용하기에 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어일수록 높은 값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
      "[[0.57735027 0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.52640543 0.         0.66767854\n",
      "  0.         0.52640543 0.         0.        ]\n",
      " [0.         0.52640543 0.         0.52640543 0.         0.\n",
      "  0.         0.         0.66767854 0.        ]\n",
      " [0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "sentence = [text_data[3]] # ['점심 먹고 공부 해야지']\n",
    "print(tfidf_vectorizer.transform(text_data).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
