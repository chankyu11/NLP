{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 384\n",
    "EPOCHS = 3\n",
    "VERBOSE = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "op = './data_out/KOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string, string_1, string_2):\n",
    "    # loss \n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[string_1])\n",
    "    plt.plot(history.history[string_2])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, string_1, string_2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "np.random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", lowercase=False)\n",
    "save_path = \"bert-base-multilingual-cased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(\"bert-base-multilingual-cased/vocab.txt\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\"\n",
    "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
    "eval_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json\"\n",
    "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-12-09 16:15:01--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.96.38\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.96.38|:443... connected.\n",
      "ERROR: cannot verify s3.amazonaws.com's certificate, issued by 'CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to s3.amazonaws.com insecurely, use `--no-check-certificate'.\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./bert-base-multilingual-cased/ https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-12-09 16:15:02--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-tf_model.h5\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.96.38\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.96.38|:443... connected.\n",
      "ERROR: cannot verify s3.amazonaws.com's certificate, issued by 'CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to s3.amazonaws.com insecurely, use `--no-check-certificate'.\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./bert-base-multilingual-cased/ https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-tf_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer_text = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "        if end_char_idx >= len(context):\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "\n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "\n",
    "        if len(ans_token_idx) == 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                squad_eg = SquadExample(\n",
    "                    question, context, start_char_idx, answer_text\n",
    "                )\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = [\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"],\n",
    "    ]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60407 training points created.\n",
      "5774 evaluation points created.\n"
     ]
    }
   ],
   "source": [
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)\n",
    "\n",
    "\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBERTQuestionAnswering(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBERTQuestionAnswering, self).__init__()\n",
    "        \n",
    "        self.encoder = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.start_logit = tf.keras.layers.Dense(num_class, name=\"start_logit\", use_bias=False)\n",
    "        self.end_logit = tf.keras.layers.Dense(num_class, name=\"end_logit\", use_bias=False)\n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.softmax = tf.keras.layers.Activation(tf.keras.activations.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        embedding = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n",
    "        start_logits = self.start_logit(embedding)\n",
    "        start_logits = self.flatten(start_logits)\n",
    "        \n",
    "        end_logits = self.end_logit(embedding)\n",
    "        end_logits = self.flatten(end_logits)\n",
    "        \n",
    "        start_probs = self.softmax(start_logits)\n",
    "        end_probs = self.softmax(end_logits)\n",
    "    \n",
    "        return start_probs, end_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model = TFBERTQuestionAnswering(model_name='./bert-base-multilingual-cased/',dir_path='bert_ckpt', num_class=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_answer(s):    \n",
    "    def remove_(text):\n",
    "        ''' 불필요한 기호 제거 '''\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('《', \" \", text)\n",
    "        text = re.sub('》', \" \", text)\n",
    "        text = re.sub('<', \" \", text)\n",
    "        text = re.sub('>', \" \", text) \n",
    "        text = re.sub('〈', \" \", text)\n",
    "        text = re.sub('〉', \" \", text)   \n",
    "        text = re.sub(\"\\(\", \" \", text)\n",
    "        text = re.sub(\"\\)\", \" \", text)\n",
    "        text = re.sub(\"‘\", \" \", text)\n",
    "        text = re.sub(\"’\", \" \", text)      \n",
    "        return text\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_punc(lower(remove_(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactMatch(keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "\n",
    "            normalized_pred_ans = normalized_answer(pred_ans)\n",
    "            normalized_true_ans = normalized_answer(squad_eg.answer_text)\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_callback = ExactMatch(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.compile(optimizer=optimizer, loss=[loss, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/KOR\\tf2_bert_korquad -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_korquad\"\n",
    "\n",
    "checkpoint_path = os.path.join(op, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "\n",
      "epoch=1, exact match score=0.14\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1875/1875 - 1763s - loss: 8.7635 - output_1_loss: 4.3611 - output_2_loss: 4.4024\n",
      "Epoch 2/3\n",
      "\n",
      "epoch=2, exact match score=0.13\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1875/1875 - 1760s - loss: 8.5335 - output_1_loss: 4.2433 - output_2_loss: 4.2901\n",
      "Epoch 3/3\n",
      "\n",
      "epoch=3, exact match score=0.13\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1875/1875 - 1760s - loss: 8.3943 - output_1_loss: 4.1715 - output_2_loss: 4.2229\n"
     ]
    }
   ],
   "source": [
    "history = korquad_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=VERBOSE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[exact_match_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [8.763504981994629, 8.533476829528809, 8.394327163696289], 'output_1_loss': [4.361113548278809, 4.243335723876953, 4.171474456787109], 'output_2_loss': [4.402388572692871, 4.290146350860596, 4.222856521606445]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss', 'output_1_loss', 'output_2_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
