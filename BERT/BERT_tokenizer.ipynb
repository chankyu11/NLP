{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e962f712f649358cf9954a8da0e24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=995526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 버트의 다국적 토크나이저\n",
    "# from transformers import *\n",
    "\n",
    "# token = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 버트 문장 전처리 실행하지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids = 문장을 토크나이즈해서 인덱스 값으로 변환한다. 일반적으로 버트에서는 단어를 서브워드의 단위로 변환시키는 워드 피스 토크나이저를             활용한다.\n",
    "\n",
    "attention_mask = 어텐션 마스크는 패딩된 부분에 대해 학습에 영향을 받지 않기 위해 처리해주는 입력값이다. 버트 토크나이저에서 1은 어텐션에                    영향을 받는 토큰을, 0은 영향을 받지 않는 토큰\n",
    "\n",
    "token_type_ids = 두 개의 시퀀스를 입력으로 활용할 때 0과 1로 문장의 토큰 값을 분리.\n",
    "                 [CLS]는 문장의 시작을 의미하며, [SEP]은 문장이 분리되는 부분을 의미하는 토큰이다.\n",
    "                 \n",
    "                 예1) [CLS] SEQ_A [SEP]\n",
    "                 [0, 0, 0, 0, ```]\n",
    "                 \n",
    "                 예2) [CLS] SEQ_A [SEP] SEQ_B [SEP]\n",
    "                 [0, 0, 0, 0, 0, 0,..., 1, 1, 1, 1,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode_plus는 버트에서 필요한 입력 형태로 변환하는 것뿐만 아니라 문장을 최대 길이에 맞게 패딩까지 해주며, 결괏값은 딕셔너리로 출력.\n",
    "\n",
    "아래 코드는 encode_plus의 변환순서이다.\n",
    "\n",
    "1. 문장을 토크나이징한다.\n",
    "\n",
    "2. add_special_tokens를 true로 지정하면 토큰의 시작점에서 '[CLS]' 토큰, 토큰의 마지막에 '[SEP]'토큰을 붙인다.\n",
    "\n",
    "3. 각 토큰을 인덱스로 변환한다.\n",
    "\n",
    "4. max_length에 MAX_LEN 최대 길이에 따라 문장의 길이를 맞추는 작업을 진행하고, pad_to_max_length 기능을 통해 MAX_LEN의\n",
    "   길이에 미치지 못하는 문장에 패딩을 적용한다.\n",
    "   \n",
    "5. return_attention_mask 기능을 통해 어텐션 마스크를 생성한다.\n",
    "\n",
    "6. 토큰 타입은 문장이 1개일 경우 0으로, 문장이 2개일 경우 0, 1로 구분해서 생성한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                    text = sent,\n",
    "                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                    max_length = MAX_LEN,\n",
    "                    pad_to_max_length = True,\n",
    "                    return_attention_mask = True)\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
